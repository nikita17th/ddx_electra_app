{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 64102,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015600137281208074,
      "grad_norm": 0.02425582893192768,
      "learning_rate": 1.5598190609889256e-06,
      "loss": 0.0566,
      "step": 500
    },
    {
      "epoch": 0.03120027456241615,
      "grad_norm": 0.027483806014060974,
      "learning_rate": 3.119638121977851e-06,
      "loss": 0.0562,
      "step": 1000
    },
    {
      "epoch": 0.046800411843624226,
      "grad_norm": 0.026035383343696594,
      "learning_rate": 4.679457182966776e-06,
      "loss": 0.0564,
      "step": 1500
    },
    {
      "epoch": 0.0624005491248323,
      "grad_norm": 0.025846727192401886,
      "learning_rate": 6.239276243955702e-06,
      "loss": 0.0566,
      "step": 2000
    },
    {
      "epoch": 0.07800068640604037,
      "grad_norm": 0.04579394683241844,
      "learning_rate": 7.799095304944627e-06,
      "loss": 0.0562,
      "step": 2500
    },
    {
      "epoch": 0.09360082368724845,
      "grad_norm": 0.03972073644399643,
      "learning_rate": 9.358914365933552e-06,
      "loss": 0.0562,
      "step": 3000
    },
    {
      "epoch": 0.10920096096845652,
      "grad_norm": 0.024789590388536453,
      "learning_rate": 1.0918733426922479e-05,
      "loss": 0.0563,
      "step": 3500
    },
    {
      "epoch": 0.1248010982496646,
      "grad_norm": 0.042673785239458084,
      "learning_rate": 1.2478552487911404e-05,
      "loss": 0.0562,
      "step": 4000
    },
    {
      "epoch": 0.14040123553087266,
      "grad_norm": 0.02956431545317173,
      "learning_rate": 1.403837154890033e-05,
      "loss": 0.0564,
      "step": 4500
    },
    {
      "epoch": 0.15600137281208074,
      "grad_norm": 0.03762111812829971,
      "learning_rate": 1.5598190609889253e-05,
      "loss": 0.0562,
      "step": 5000
    },
    {
      "epoch": 0.17160151009328883,
      "grad_norm": 0.03074975125491619,
      "learning_rate": 1.715800967087818e-05,
      "loss": 0.0564,
      "step": 5500
    },
    {
      "epoch": 0.1872016473744969,
      "grad_norm": 0.034196335822343826,
      "learning_rate": 1.8717828731867104e-05,
      "loss": 0.0566,
      "step": 6000
    },
    {
      "epoch": 0.20280178465570498,
      "grad_norm": 0.020769160240888596,
      "learning_rate": 1.9969145967308595e-05,
      "loss": 0.0564,
      "step": 6500
    },
    {
      "epoch": 0.21840192193691305,
      "grad_norm": 0.023183394223451614,
      "learning_rate": 1.9795808704997316e-05,
      "loss": 0.0564,
      "step": 7000
    },
    {
      "epoch": 0.23400205921812112,
      "grad_norm": 0.02537674270570278,
      "learning_rate": 1.9622471442686037e-05,
      "loss": 0.056,
      "step": 7500
    },
    {
      "epoch": 0.2496021964993292,
      "grad_norm": 0.025694724172353745,
      "learning_rate": 1.9449134180374754e-05,
      "loss": 0.0558,
      "step": 8000
    },
    {
      "epoch": 0.26520233378053726,
      "grad_norm": 0.04022267833352089,
      "learning_rate": 1.927579691806348e-05,
      "loss": 0.0564,
      "step": 8500
    },
    {
      "epoch": 0.28080247106174533,
      "grad_norm": 0.020400751382112503,
      "learning_rate": 1.91024596557522e-05,
      "loss": 0.0564,
      "step": 9000
    },
    {
      "epoch": 0.2964026083429534,
      "grad_norm": 0.03671906143426895,
      "learning_rate": 1.892912239344092e-05,
      "loss": 0.0563,
      "step": 9500
    },
    {
      "epoch": 0.31200274562416147,
      "grad_norm": 0.05259978026151657,
      "learning_rate": 1.875578513112964e-05,
      "loss": 0.0565,
      "step": 10000
    },
    {
      "epoch": 0.32760288290536954,
      "grad_norm": 0.0209348164498806,
      "learning_rate": 1.8582447868818362e-05,
      "loss": 0.0567,
      "step": 10500
    },
    {
      "epoch": 0.34320302018657767,
      "grad_norm": 0.0469975620508194,
      "learning_rate": 1.840911060650708e-05,
      "loss": 0.0565,
      "step": 11000
    },
    {
      "epoch": 0.35880315746778574,
      "grad_norm": 0.022463826462626457,
      "learning_rate": 1.8235773344195804e-05,
      "loss": 0.0563,
      "step": 11500
    },
    {
      "epoch": 0.3744032947489938,
      "grad_norm": 0.027712993323802948,
      "learning_rate": 1.8062436081884525e-05,
      "loss": 0.0564,
      "step": 12000
    },
    {
      "epoch": 0.3900034320302019,
      "grad_norm": 0.03129306808114052,
      "learning_rate": 1.7889098819573246e-05,
      "loss": 0.0565,
      "step": 12500
    },
    {
      "epoch": 0.40560356931140995,
      "grad_norm": 0.030638784170150757,
      "learning_rate": 1.7715761557261967e-05,
      "loss": 0.0563,
      "step": 13000
    },
    {
      "epoch": 0.421203706592618,
      "grad_norm": 0.019867178052663803,
      "learning_rate": 1.7542424294950685e-05,
      "loss": 0.056,
      "step": 13500
    },
    {
      "epoch": 0.4368038438738261,
      "grad_norm": 0.029291925951838493,
      "learning_rate": 1.736908703263941e-05,
      "loss": 0.0566,
      "step": 14000
    },
    {
      "epoch": 0.45240398115503416,
      "grad_norm": 0.021834133192896843,
      "learning_rate": 1.719574977032813e-05,
      "loss": 0.0564,
      "step": 14500
    },
    {
      "epoch": 0.46800411843624223,
      "grad_norm": 0.06867127865552902,
      "learning_rate": 1.702241250801685e-05,
      "loss": 0.0564,
      "step": 15000
    },
    {
      "epoch": 0.4836042557174503,
      "grad_norm": 0.03551821410655975,
      "learning_rate": 1.6849075245705572e-05,
      "loss": 0.0561,
      "step": 15500
    },
    {
      "epoch": 0.4992043929986584,
      "grad_norm": 0.02370487153530121,
      "learning_rate": 1.6675737983394293e-05,
      "loss": 0.0561,
      "step": 16000
    },
    {
      "epoch": 0.5148045302798665,
      "grad_norm": 0.029124414548277855,
      "learning_rate": 1.650240072108301e-05,
      "loss": 0.0566,
      "step": 16500
    },
    {
      "epoch": 0.5304046675610745,
      "grad_norm": 0.024921828880906105,
      "learning_rate": 1.6329063458771735e-05,
      "loss": 0.0563,
      "step": 17000
    },
    {
      "epoch": 0.5460048048422826,
      "grad_norm": 0.05796873942017555,
      "learning_rate": 1.6155726196460455e-05,
      "loss": 0.0563,
      "step": 17500
    },
    {
      "epoch": 0.5616049421234907,
      "grad_norm": 0.03999519720673561,
      "learning_rate": 1.5982388934149176e-05,
      "loss": 0.0564,
      "step": 18000
    },
    {
      "epoch": 0.5772050794046988,
      "grad_norm": 0.09550368040800095,
      "learning_rate": 1.5809051671837897e-05,
      "loss": 0.0562,
      "step": 18500
    },
    {
      "epoch": 0.5928052166859068,
      "grad_norm": 0.029313942417502403,
      "learning_rate": 1.563571440952662e-05,
      "loss": 0.0561,
      "step": 19000
    },
    {
      "epoch": 0.6084053539671149,
      "grad_norm": 0.03429710119962692,
      "learning_rate": 1.5462377147215336e-05,
      "loss": 0.0562,
      "step": 19500
    },
    {
      "epoch": 0.6240054912483229,
      "grad_norm": 0.018741467967629433,
      "learning_rate": 1.528903988490406e-05,
      "loss": 0.0562,
      "step": 20000
    },
    {
      "epoch": 0.6396056285295311,
      "grad_norm": 0.028471948578953743,
      "learning_rate": 1.5115702622592781e-05,
      "loss": 0.0565,
      "step": 20500
    },
    {
      "epoch": 0.6552057658107391,
      "grad_norm": 0.03861984238028526,
      "learning_rate": 1.49423653602815e-05,
      "loss": 0.0562,
      "step": 21000
    },
    {
      "epoch": 0.6708059030919472,
      "grad_norm": 0.03335488587617874,
      "learning_rate": 1.4769028097970221e-05,
      "loss": 0.0559,
      "step": 21500
    },
    {
      "epoch": 0.6864060403731553,
      "grad_norm": 0.039545830339193344,
      "learning_rate": 1.4595690835658942e-05,
      "loss": 0.0563,
      "step": 22000
    },
    {
      "epoch": 0.7020061776543634,
      "grad_norm": 0.027762308716773987,
      "learning_rate": 1.4422353573347663e-05,
      "loss": 0.0563,
      "step": 22500
    },
    {
      "epoch": 0.7176063149355715,
      "grad_norm": 0.019218789413571358,
      "learning_rate": 1.4249016311036386e-05,
      "loss": 0.056,
      "step": 23000
    },
    {
      "epoch": 0.7332064522167795,
      "grad_norm": 0.037665627896785736,
      "learning_rate": 1.4075679048725107e-05,
      "loss": 0.0563,
      "step": 23500
    },
    {
      "epoch": 0.7488065894979876,
      "grad_norm": 0.03002416342496872,
      "learning_rate": 1.3902341786413826e-05,
      "loss": 0.0561,
      "step": 24000
    },
    {
      "epoch": 0.7644067267791956,
      "grad_norm": 0.02649868279695511,
      "learning_rate": 1.3729004524102547e-05,
      "loss": 0.0562,
      "step": 24500
    },
    {
      "epoch": 0.7800068640604038,
      "grad_norm": 0.02332829311490059,
      "learning_rate": 1.3555667261791268e-05,
      "loss": 0.0563,
      "step": 25000
    },
    {
      "epoch": 0.7956070013416118,
      "grad_norm": 0.027992092072963715,
      "learning_rate": 1.3382329999479989e-05,
      "loss": 0.0563,
      "step": 25500
    },
    {
      "epoch": 0.8112071386228199,
      "grad_norm": 0.03617173060774803,
      "learning_rate": 1.3208992737168711e-05,
      "loss": 0.0564,
      "step": 26000
    },
    {
      "epoch": 0.8268072759040279,
      "grad_norm": 0.02587686851620674,
      "learning_rate": 1.303565547485743e-05,
      "loss": 0.0563,
      "step": 26500
    },
    {
      "epoch": 0.842407413185236,
      "grad_norm": 0.04638992249965668,
      "learning_rate": 1.2862318212546152e-05,
      "loss": 0.0565,
      "step": 27000
    },
    {
      "epoch": 0.8580075504664441,
      "grad_norm": 0.018354127183556557,
      "learning_rate": 1.2688980950234873e-05,
      "loss": 0.0563,
      "step": 27500
    },
    {
      "epoch": 0.8736076877476522,
      "grad_norm": 0.032424673438072205,
      "learning_rate": 1.2515643687923594e-05,
      "loss": 0.0561,
      "step": 28000
    },
    {
      "epoch": 0.8892078250288602,
      "grad_norm": 0.027287516742944717,
      "learning_rate": 1.2342306425612316e-05,
      "loss": 0.0564,
      "step": 28500
    },
    {
      "epoch": 0.9048079623100683,
      "grad_norm": 0.03466707840561867,
      "learning_rate": 1.2168969163301037e-05,
      "loss": 0.0563,
      "step": 29000
    },
    {
      "epoch": 0.9204080995912765,
      "grad_norm": 0.02849637344479561,
      "learning_rate": 1.1995631900989756e-05,
      "loss": 0.0564,
      "step": 29500
    },
    {
      "epoch": 0.9360082368724845,
      "grad_norm": 0.018913881853222847,
      "learning_rate": 1.1822294638678477e-05,
      "loss": 0.0564,
      "step": 30000
    },
    {
      "epoch": 0.9516083741536926,
      "grad_norm": 0.02545115165412426,
      "learning_rate": 1.1648957376367198e-05,
      "loss": 0.0561,
      "step": 30500
    },
    {
      "epoch": 0.9672085114349006,
      "grad_norm": 0.02381085976958275,
      "learning_rate": 1.147562011405592e-05,
      "loss": 0.0564,
      "step": 31000
    },
    {
      "epoch": 0.9828086487161087,
      "grad_norm": 0.07340686768293381,
      "learning_rate": 1.1302282851744642e-05,
      "loss": 0.0562,
      "step": 31500
    },
    {
      "epoch": 0.9984087859973168,
      "grad_norm": 0.025523466989398003,
      "learning_rate": 1.1128945589433363e-05,
      "loss": 0.0561,
      "step": 32000
    },
    {
      "epoch": 1.0,
      "eval_DDF1": 0.9575241442381375,
      "eval_DDP": 0.9538733809369968,
      "eval_DDR": 0.9612029600659884,
      "eval_loss": 0.05574287101626396,
      "eval_mAP": 0.9780398412660345,
      "eval_runtime": 544.2692,
      "eval_samples_per_second": 243.35,
      "eval_steps_per_second": 3.803,
      "step": 32051
    },
    {
      "epoch": 1.0140089232785248,
      "grad_norm": 0.03159613907337189,
      "learning_rate": 1.0955608327122082e-05,
      "loss": 0.0563,
      "step": 32500
    },
    {
      "epoch": 1.029609060559733,
      "grad_norm": 0.02268943004310131,
      "learning_rate": 1.0782271064810803e-05,
      "loss": 0.0563,
      "step": 33000
    },
    {
      "epoch": 1.045209197840941,
      "grad_norm": 0.024805782362818718,
      "learning_rate": 1.0608933802499524e-05,
      "loss": 0.0562,
      "step": 33500
    },
    {
      "epoch": 1.060809335122149,
      "grad_norm": 0.024218663573265076,
      "learning_rate": 1.0435596540188245e-05,
      "loss": 0.0561,
      "step": 34000
    },
    {
      "epoch": 1.076409472403357,
      "grad_norm": 0.028660675510764122,
      "learning_rate": 1.0262259277876967e-05,
      "loss": 0.056,
      "step": 34500
    },
    {
      "epoch": 1.0920096096845653,
      "grad_norm": 0.03523889183998108,
      "learning_rate": 1.0088922015565687e-05,
      "loss": 0.0563,
      "step": 35000
    },
    {
      "epoch": 1.1076097469657733,
      "grad_norm": 0.02472749538719654,
      "learning_rate": 9.915584753254408e-06,
      "loss": 0.0562,
      "step": 35500
    },
    {
      "epoch": 1.1232098842469813,
      "grad_norm": 0.01699870079755783,
      "learning_rate": 9.742247490943129e-06,
      "loss": 0.0562,
      "step": 36000
    },
    {
      "epoch": 1.1388100215281893,
      "grad_norm": 0.04784519225358963,
      "learning_rate": 9.56891022863185e-06,
      "loss": 0.0562,
      "step": 36500
    },
    {
      "epoch": 1.1544101588093976,
      "grad_norm": 0.02799856849014759,
      "learning_rate": 9.39557296632057e-06,
      "loss": 0.0562,
      "step": 37000
    },
    {
      "epoch": 1.1700102960906056,
      "grad_norm": 0.025285182520747185,
      "learning_rate": 9.222235704009291e-06,
      "loss": 0.0561,
      "step": 37500
    },
    {
      "epoch": 1.1856104333718136,
      "grad_norm": 0.022428086027503014,
      "learning_rate": 9.048898441698012e-06,
      "loss": 0.0563,
      "step": 38000
    },
    {
      "epoch": 1.2012105706530218,
      "grad_norm": 0.023762164637446404,
      "learning_rate": 8.875561179386733e-06,
      "loss": 0.0562,
      "step": 38500
    },
    {
      "epoch": 1.2168107079342299,
      "grad_norm": 0.022949956357479095,
      "learning_rate": 8.702223917075454e-06,
      "loss": 0.0564,
      "step": 39000
    },
    {
      "epoch": 1.2324108452154379,
      "grad_norm": 0.03962956741452217,
      "learning_rate": 8.528886654764175e-06,
      "loss": 0.0563,
      "step": 39500
    },
    {
      "epoch": 1.2480109824966459,
      "grad_norm": 0.036963678896427155,
      "learning_rate": 8.355549392452896e-06,
      "loss": 0.0559,
      "step": 40000
    },
    {
      "epoch": 1.2636111197778541,
      "grad_norm": 0.024059414863586426,
      "learning_rate": 8.182212130141617e-06,
      "loss": 0.0562,
      "step": 40500
    },
    {
      "epoch": 1.2792112570590621,
      "grad_norm": 0.04129304736852646,
      "learning_rate": 8.008874867830338e-06,
      "loss": 0.0562,
      "step": 41000
    },
    {
      "epoch": 1.2948113943402701,
      "grad_norm": 0.029505565762519836,
      "learning_rate": 7.835537605519059e-06,
      "loss": 0.0564,
      "step": 41500
    },
    {
      "epoch": 1.3104115316214782,
      "grad_norm": 0.026222610846161842,
      "learning_rate": 7.66220034320778e-06,
      "loss": 0.0559,
      "step": 42000
    },
    {
      "epoch": 1.3260116689026864,
      "grad_norm": 0.02767663635313511,
      "learning_rate": 7.488863080896502e-06,
      "loss": 0.0563,
      "step": 42500
    },
    {
      "epoch": 1.3416118061838944,
      "grad_norm": 0.021040035411715508,
      "learning_rate": 7.315525818585222e-06,
      "loss": 0.0564,
      "step": 43000
    },
    {
      "epoch": 1.3572119434651024,
      "grad_norm": 0.027107691392302513,
      "learning_rate": 7.142188556273943e-06,
      "loss": 0.056,
      "step": 43500
    },
    {
      "epoch": 1.3728120807463107,
      "grad_norm": 0.045104432851076126,
      "learning_rate": 6.968851293962664e-06,
      "loss": 0.0563,
      "step": 44000
    },
    {
      "epoch": 1.3884122180275187,
      "grad_norm": 0.025931045413017273,
      "learning_rate": 6.795514031651385e-06,
      "loss": 0.0562,
      "step": 44500
    },
    {
      "epoch": 1.4040123553087267,
      "grad_norm": 0.020731376484036446,
      "learning_rate": 6.622176769340105e-06,
      "loss": 0.0563,
      "step": 45000
    },
    {
      "epoch": 1.4196124925899347,
      "grad_norm": 0.02442084439098835,
      "learning_rate": 6.4488395070288265e-06,
      "loss": 0.0562,
      "step": 45500
    },
    {
      "epoch": 1.4352126298711427,
      "grad_norm": 0.023906821385025978,
      "learning_rate": 6.275502244717547e-06,
      "loss": 0.056,
      "step": 46000
    },
    {
      "epoch": 1.450812767152351,
      "grad_norm": 0.03866035118699074,
      "learning_rate": 6.1021649824062675e-06,
      "loss": 0.0561,
      "step": 46500
    },
    {
      "epoch": 1.466412904433559,
      "grad_norm": 0.03767324239015579,
      "learning_rate": 5.928827720094989e-06,
      "loss": 0.0561,
      "step": 47000
    },
    {
      "epoch": 1.482013041714767,
      "grad_norm": 0.03048107773065567,
      "learning_rate": 5.75549045778371e-06,
      "loss": 0.0563,
      "step": 47500
    },
    {
      "epoch": 1.4976131789959752,
      "grad_norm": 0.023430300876498222,
      "learning_rate": 5.58215319547243e-06,
      "loss": 0.0562,
      "step": 48000
    },
    {
      "epoch": 1.5132133162771833,
      "grad_norm": 0.039451953023672104,
      "learning_rate": 5.408815933161152e-06,
      "loss": 0.056,
      "step": 48500
    },
    {
      "epoch": 1.5288134535583913,
      "grad_norm": 0.02468113973736763,
      "learning_rate": 5.235478670849873e-06,
      "loss": 0.0562,
      "step": 49000
    },
    {
      "epoch": 1.5444135908395995,
      "grad_norm": 0.02687816694378853,
      "learning_rate": 5.062141408538595e-06,
      "loss": 0.056,
      "step": 49500
    },
    {
      "epoch": 1.5600137281208073,
      "grad_norm": 0.023054588586091995,
      "learning_rate": 4.888804146227315e-06,
      "loss": 0.0563,
      "step": 50000
    },
    {
      "epoch": 1.5756138654020155,
      "grad_norm": 0.016712909564375877,
      "learning_rate": 4.715466883916036e-06,
      "loss": 0.0561,
      "step": 50500
    },
    {
      "epoch": 1.5912140026832238,
      "grad_norm": 0.04303848743438721,
      "learning_rate": 4.542129621604757e-06,
      "loss": 0.0563,
      "step": 51000
    },
    {
      "epoch": 1.6068141399644316,
      "grad_norm": 0.02500000037252903,
      "learning_rate": 4.368792359293478e-06,
      "loss": 0.0561,
      "step": 51500
    },
    {
      "epoch": 1.6224142772456398,
      "grad_norm": 0.033301785588264465,
      "learning_rate": 4.195455096982199e-06,
      "loss": 0.0559,
      "step": 52000
    },
    {
      "epoch": 1.6380144145268478,
      "grad_norm": 0.02069319784641266,
      "learning_rate": 4.02211783467092e-06,
      "loss": 0.0564,
      "step": 52500
    },
    {
      "epoch": 1.6536145518080558,
      "grad_norm": 0.0221644788980484,
      "learning_rate": 3.848780572359641e-06,
      "loss": 0.0562,
      "step": 53000
    },
    {
      "epoch": 1.669214689089264,
      "grad_norm": 0.05392415076494217,
      "learning_rate": 3.6754433100483615e-06,
      "loss": 0.0559,
      "step": 53500
    },
    {
      "epoch": 1.684814826370472,
      "grad_norm": 0.039842959493398666,
      "learning_rate": 3.502106047737082e-06,
      "loss": 0.0562,
      "step": 54000
    },
    {
      "epoch": 1.70041496365168,
      "grad_norm": 0.043439287692308426,
      "learning_rate": 3.3287687854258034e-06,
      "loss": 0.0562,
      "step": 54500
    },
    {
      "epoch": 1.7160151009328883,
      "grad_norm": 0.026501350104808807,
      "learning_rate": 3.1554315231145244e-06,
      "loss": 0.0563,
      "step": 55000
    },
    {
      "epoch": 1.7316152382140961,
      "grad_norm": 0.07785747945308685,
      "learning_rate": 2.982094260803245e-06,
      "loss": 0.0558,
      "step": 55500
    },
    {
      "epoch": 1.7472153754953044,
      "grad_norm": 0.022660905495285988,
      "learning_rate": 2.8087569984919662e-06,
      "loss": 0.0563,
      "step": 56000
    },
    {
      "epoch": 1.7628155127765124,
      "grad_norm": 0.02159314788877964,
      "learning_rate": 2.635419736180687e-06,
      "loss": 0.0563,
      "step": 56500
    },
    {
      "epoch": 1.7784156500577204,
      "grad_norm": 0.018574148416519165,
      "learning_rate": 2.462082473869408e-06,
      "loss": 0.0561,
      "step": 57000
    },
    {
      "epoch": 1.7940157873389286,
      "grad_norm": 0.030832523480057716,
      "learning_rate": 2.2887452115581286e-06,
      "loss": 0.0562,
      "step": 57500
    },
    {
      "epoch": 1.8096159246201367,
      "grad_norm": 0.023917503654956818,
      "learning_rate": 2.11540794924685e-06,
      "loss": 0.0562,
      "step": 58000
    },
    {
      "epoch": 1.8252160619013447,
      "grad_norm": 0.02970597706735134,
      "learning_rate": 1.9420706869355705e-06,
      "loss": 0.0558,
      "step": 58500
    },
    {
      "epoch": 1.840816199182553,
      "grad_norm": 0.029688837006688118,
      "learning_rate": 1.7687334246242915e-06,
      "loss": 0.0562,
      "step": 59000
    },
    {
      "epoch": 1.856416336463761,
      "grad_norm": 0.025952983647584915,
      "learning_rate": 1.5953961623130126e-06,
      "loss": 0.0559,
      "step": 59500
    },
    {
      "epoch": 1.872016473744969,
      "grad_norm": 0.025000549852848053,
      "learning_rate": 1.4220589000017336e-06,
      "loss": 0.0561,
      "step": 60000
    },
    {
      "epoch": 1.8876166110261772,
      "grad_norm": 0.02514008805155754,
      "learning_rate": 1.2487216376904545e-06,
      "loss": 0.056,
      "step": 60500
    },
    {
      "epoch": 1.903216748307385,
      "grad_norm": 0.02084769308567047,
      "learning_rate": 1.0753843753791754e-06,
      "loss": 0.0562,
      "step": 61000
    },
    {
      "epoch": 1.9188168855885932,
      "grad_norm": 0.04788012430071831,
      "learning_rate": 9.020471130678962e-07,
      "loss": 0.0559,
      "step": 61500
    },
    {
      "epoch": 1.9344170228698012,
      "grad_norm": 0.02283090353012085,
      "learning_rate": 7.287098507566172e-07,
      "loss": 0.0561,
      "step": 62000
    },
    {
      "epoch": 1.9500171601510092,
      "grad_norm": 0.02740205079317093,
      "learning_rate": 5.553725884453382e-07,
      "loss": 0.056,
      "step": 62500
    },
    {
      "epoch": 1.9656172974322175,
      "grad_norm": 0.03265479952096939,
      "learning_rate": 3.8203532613405904e-07,
      "loss": 0.0561,
      "step": 63000
    },
    {
      "epoch": 1.9812174347134255,
      "grad_norm": 0.016719140112400055,
      "learning_rate": 2.0869806382278e-07,
      "loss": 0.0563,
      "step": 63500
    },
    {
      "epoch": 1.9968175719946335,
      "grad_norm": 0.04712507873773575,
      "learning_rate": 3.536080151150093e-08,
      "loss": 0.056,
      "step": 64000
    }
  ],
  "logging_steps": 500,
  "max_steps": 64102,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.66661777219272e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
