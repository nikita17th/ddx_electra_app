{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    ElectraForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    ElectraConfig\n",
    ")"
   ],
   "id": "fe22988060825413"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ],
   "id": "564dcd5c7c624da9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "class CustomElectra(ElectraForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Механизм внимания с 4 головами\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=config.hidden_size,\n",
    "            num_heads=4,\n",
    "            dropout=0.3,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, config.num_labels)\n",
    "        )\n",
    "        self.loss_fct = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.electra(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=False\n",
    "        )\n",
    "\n",
    "        # Применение механизма внимания\n",
    "        attn_output, _ = self.attention(\n",
    "            outputs.last_hidden_state,\n",
    "            outputs.last_hidden_state,\n",
    "            outputs.last_hidden_state,\n",
    "            key_padding_mask=~attention_mask.bool()\n",
    "        )\n",
    "\n",
    "        # Усреднение с учетом внимания\n",
    "        pooled = torch.mean(attn_output, dim=1)\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fct(logits, labels.float())\n",
    "\n",
    "        return (loss, logits) if loss is not None else logits"
   ],
   "id": "c9309bb256ea3f57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, label_to_index):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_to_index = label_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        text = self._preprocess_row(row)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=300\n",
    "        )\n",
    "\n",
    "        labels = torch.zeros(len(self.label_to_index))\n",
    "        diagnosis = ast.literal_eval(row['DIFFERENTIAL_DIAGNOSIS'])\n",
    "\n",
    "        for disease, probability in diagnosis:\n",
    "            if disease in self.label_to_index:\n",
    "                index = self.label_to_index[disease]\n",
    "                labels[index] = probability\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0).to(device),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0).to(device),\n",
    "            'labels': labels.to(device)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_row(row):\n",
    "        age = str(row['AGE'])\n",
    "        sex = row['SEX']\n",
    "        evidences = ' '.join(ast.literal_eval(row['EVIDENCES']))\n",
    "        initial_evidence = row['INITIAL_EVIDENCE']\n",
    "        return f\"[AGE] {age} [SEX] {sex} [EVIDENCES] {evidences} [INITIAL] {initial_evidence}\""
   ],
   "id": "d53479ee99bf5227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_evidences_codes(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    all_codes = []\n",
    "    seen = set()\n",
    "\n",
    "    for evidence_id, evidence_data in data.items():\n",
    "        if evidence_id not in seen:\n",
    "            all_codes.append(evidence_id)\n",
    "            seen.add(evidence_id)\n",
    "\n",
    "        possible_values = evidence_data.get(\"possible-values\", [])\n",
    "        for val in possible_values:\n",
    "            code = f\"{evidence_id}_@_{val}\"\n",
    "            if code not in seen:\n",
    "                all_codes.append(code)\n",
    "                seen.add(code)\n",
    "\n",
    "    return all_codes"
   ],
   "id": "954c74c7fb798fef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_ddx_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Преобразуем логиты в вероятности\n",
    "    probs = 1 / (1 + np.exp(-logits))  # Sigmoid через numpy\n",
    "    predictions = probs > 0.02  # Порог остается 0.02\n",
    "\n",
    "    recall_values = []\n",
    "    precision_values = []\n",
    "\n",
    "    for true, pred in zip(labels, predictions):\n",
    "        true_indices = set(np.where(true > 0)[0].tolist())\n",
    "        pred_indices = set(np.where(pred)[0].tolist())\n",
    "\n",
    "        # Recall (DDR)\n",
    "        if len(true_indices) > 0:\n",
    "            recall = len(true_indices & pred_indices) / len(true_indices)\n",
    "        else:\n",
    "            recall = 0\n",
    "        recall_values.append(recall)\n",
    "\n",
    "        # Precision (DDP)\n",
    "        if len(pred_indices) > 0:\n",
    "            precision = len(true_indices & pred_indices) / len(pred_indices)\n",
    "        else:\n",
    "            precision = 0\n",
    "        precision_values.append(precision)\n",
    "\n",
    "    DDR = np.mean(recall_values)\n",
    "    DDP = np.mean(precision_values)\n",
    "    DDF1 = 2 * DDR * DDP / (DDR + DDP) if (DDR + DDP) > 0 else 0\n",
    "\n",
    "    labels_binary = (labels >= 0.05).astype(int)\n",
    "    valid_classes = np.where(labels_binary.sum(axis=0) > 0)[0]\n",
    "    if len(valid_classes) == 0:\n",
    "        mAP = 0.0  # Все классы \"пустые\"\n",
    "    else:\n",
    "        mAP = average_precision_score(\n",
    "            labels_binary[:, valid_classes],\n",
    "            probs[:, valid_classes],\n",
    "            average='macro'\n",
    "        )\n",
    "    return {\"DDR\": DDR, \"DDP\": DDP, \"DDF1\": DDF1, \"mAP\": mAP}"
   ],
   "id": "b2573074fb846a2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "evidences_codes = load_evidences_codes('release_evidences.json')\n",
    "print(evidences_codes)\n",
    "tokenizer.add_tokens(evidences_codes)\n",
    "\n",
    "train_data = pd.read_csv('release_train_patients.csv')\n",
    "val_data = pd.read_csv('release_validate_patients.csv')\n",
    "\n",
    "# Обработка меток\n",
    "labels_file = 'labels.json'\n",
    "if os.path.exists(labels_file):\n",
    "    with open(labels_file, 'r') as f:\n",
    "        all_labels = json.load(f)\n",
    "else:\n",
    "    all_labels = sorted({\n",
    "        disease for diagnoses in train_data['DIFFERENTIAL_DIAGNOSIS']\n",
    "        for disease, _ in ast.literal_eval(diagnoses)\n",
    "    })\n",
    "    with open(labels_file, 'w') as f:\n",
    "        json.dump(all_labels, f)\n",
    "\n",
    "label_to_index = {label: idx for idx, label in enumerate(all_labels)}\n",
    "\n",
    "config = ElectraConfig.from_pretrained(\"google/electra-small-discriminator\")\n",
    "config.num_labels = len(all_labels)\n",
    "config.problem_type = \"multi_label_classification\"\n",
    "model = CustomElectra(config)\n",
    "model.resize_token_embeddings(len(tokenizer), mean_resizing=False)  # Важно после добавления токенов!\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = MedicalDataset(train_data, tokenizer, label_to_index)\n",
    "val_dataset = MedicalDataset(val_data, tokenizer, label_to_index)\n",
    "\n",
    "torch.mps.empty_cache()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./dd_classification_attention_v2\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=2,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=False,\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_ddx_metrics,\n",
    ")\n",
    "tokenizer.save_pretrained(\"./dd_classification_attention_v2_tokenizer\")\n",
    "trainer.train()"
   ],
   "id": "70afbea1931ae27c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./dd_classification_attention_v2_tokenizer\")\n",
    "with open('labels.json', 'r') as f:\n",
    "    all_labels = json.load(f)\n",
    "label_to_index = {label: idx for idx, label in enumerate(all_labels)}\n",
    "\n",
    "model_path = \"./dd_classification_attention_v2_11-12/checkpoint-64102\"  # Путь к сохраненной модели\n",
    "config = CustomElectra.config_class.from_pretrained(model_path)\n",
    "model = CustomElectra(config).from_pretrained(model_path)\n",
    "model.to(torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "# Загрузка новых данных для дообучения\n",
    "new_train_data = pd.read_csv('release_train_patients.csv')  # Путь к новым данным\n",
    "new_val_data = pd.read_csv('release_validate_patients.csv')      # Валидационные данные\n",
    "\n",
    "train_dataset = MedicalDataset(new_train_data, tokenizer, label_to_index)\n",
    "val_dataset = MedicalDataset(new_val_data, tokenizer, label_to_index)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./dd_classification_attention_v2_13-14\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=2,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_continued\",\n",
    "    fp16=False,\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "# Инициализация Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_ddx_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "f8dab5306d9a3dd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./dd_classification_attention_v2_tokenizer\")\n",
    "\n",
    "# Загрузка меток\n",
    "with open('../../common/labels.json', 'r') as f:\n",
    "    all_labels = json.load(f)\n",
    "label_to_index = {label: idx for idx, label in enumerate(all_labels)}\n",
    "model_path = \"./dd_classification_attention_v2_11-12/checkpoint-64102\"\n",
    "model = CustomElectra.from_pretrained(model_path).to(device)\n",
    "# model.resize_token_embeddings(len(tokenizer))  # Синхронизация токенизатора и модели\n",
    "\n",
    "# Проверка данных\n",
    "test_data = pd.read_csv('release_test_patients.csv')\n",
    "print(\"Пример данных:\", test_data.iloc[0]['DIFFERENTIAL_DIAGNOSIS'])\n",
    "\n",
    "test_dataset = MedicalDataset(test_data, tokenizer, label_to_index)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_ddx_metrics,\n",
    ")\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ],
   "id": "ad0f5b7cc58a3096"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
