{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 8000,
  "global_step": 32052,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.031199301135654563,
      "grad_norm": 0.017458278685808182,
      "learning_rate": 9.844003494321727e-07,
      "loss": 0.0556,
      "step": 500
    },
    {
      "epoch": 0.062398602271309125,
      "grad_norm": 0.008773216977715492,
      "learning_rate": 9.688006988643454e-07,
      "loss": 0.0557,
      "step": 1000
    },
    {
      "epoch": 0.09359790340696368,
      "grad_norm": 0.011808760464191437,
      "learning_rate": 9.532010482965181e-07,
      "loss": 0.0554,
      "step": 1500
    },
    {
      "epoch": 0.12479720454261825,
      "grad_norm": 0.011086142621934414,
      "learning_rate": 9.376013977286908e-07,
      "loss": 0.0555,
      "step": 2000
    },
    {
      "epoch": 0.1559965056782728,
      "grad_norm": 0.01206688117235899,
      "learning_rate": 9.220017471608635e-07,
      "loss": 0.0555,
      "step": 2500
    },
    {
      "epoch": 0.18719580681392736,
      "grad_norm": 0.014168287627398968,
      "learning_rate": 9.064020965930362e-07,
      "loss": 0.0556,
      "step": 3000
    },
    {
      "epoch": 0.21839510794958192,
      "grad_norm": 0.015909498557448387,
      "learning_rate": 8.908024460252091e-07,
      "loss": 0.0555,
      "step": 3500
    },
    {
      "epoch": 0.2495944090852365,
      "grad_norm": 0.01172549556940794,
      "learning_rate": 8.752027954573818e-07,
      "loss": 0.0551,
      "step": 4000
    },
    {
      "epoch": 0.28079371022089106,
      "grad_norm": 0.01246531493961811,
      "learning_rate": 8.596031448895544e-07,
      "loss": 0.0556,
      "step": 4500
    },
    {
      "epoch": 0.3119930113565456,
      "grad_norm": 0.013488695956766605,
      "learning_rate": 8.440034943217271e-07,
      "loss": 0.0556,
      "step": 5000
    },
    {
      "epoch": 0.34319231249220017,
      "grad_norm": 0.020554061979055405,
      "learning_rate": 8.284038437538998e-07,
      "loss": 0.0558,
      "step": 5500
    },
    {
      "epoch": 0.3743916136278547,
      "grad_norm": 0.010467629879713058,
      "learning_rate": 8.128041931860726e-07,
      "loss": 0.0555,
      "step": 6000
    },
    {
      "epoch": 0.4055909147635093,
      "grad_norm": 0.009338896721601486,
      "learning_rate": 7.972045426182454e-07,
      "loss": 0.0556,
      "step": 6500
    },
    {
      "epoch": 0.43679021589916384,
      "grad_norm": 0.011844179593026638,
      "learning_rate": 7.816048920504181e-07,
      "loss": 0.0555,
      "step": 7000
    },
    {
      "epoch": 0.46798951703481845,
      "grad_norm": 0.01566534861922264,
      "learning_rate": 7.660052414825907e-07,
      "loss": 0.0556,
      "step": 7500
    },
    {
      "epoch": 0.499188818170473,
      "grad_norm": 0.010528610087931156,
      "learning_rate": 7.504055909147635e-07,
      "loss": 0.0553,
      "step": 8000
    },
    {
      "epoch": 0.499188818170473,
      "eval_DDF1": 0.9690602831592308,
      "eval_DDP": 0.9661611772711182,
      "eval_DDR": 0.9719768397810539,
      "eval_loss": 0.05528227239847183,
      "eval_runtime": 550.3975,
      "eval_samples_per_second": 240.641,
      "eval_steps_per_second": 1.88,
      "step": 8000
    },
    {
      "epoch": 0.5303881193061275,
      "grad_norm": 0.013891707174479961,
      "learning_rate": 7.348059403469362e-07,
      "loss": 0.0556,
      "step": 8500
    },
    {
      "epoch": 0.5615874204417821,
      "grad_norm": 0.013532470911741257,
      "learning_rate": 7.192062897791089e-07,
      "loss": 0.0555,
      "step": 9000
    },
    {
      "epoch": 0.5927867215774366,
      "grad_norm": 0.010551377199590206,
      "learning_rate": 7.036066392112816e-07,
      "loss": 0.0554,
      "step": 9500
    },
    {
      "epoch": 0.6239860227130912,
      "grad_norm": 0.008051916025578976,
      "learning_rate": 6.880069886434543e-07,
      "loss": 0.0554,
      "step": 10000
    },
    {
      "epoch": 0.6551853238487458,
      "grad_norm": 0.010018927045166492,
      "learning_rate": 6.724073380756271e-07,
      "loss": 0.0556,
      "step": 10500
    },
    {
      "epoch": 0.6863846249844003,
      "grad_norm": 0.01275377906858921,
      "learning_rate": 6.568076875077998e-07,
      "loss": 0.0553,
      "step": 11000
    },
    {
      "epoch": 0.717583926120055,
      "grad_norm": 0.011773823760449886,
      "learning_rate": 6.412080369399725e-07,
      "loss": 0.0554,
      "step": 11500
    },
    {
      "epoch": 0.7487832272557094,
      "grad_norm": 0.008209646679461002,
      "learning_rate": 6.256083863721452e-07,
      "loss": 0.0555,
      "step": 12000
    },
    {
      "epoch": 0.7799825283913641,
      "grad_norm": 0.009593013674020767,
      "learning_rate": 6.10008735804318e-07,
      "loss": 0.0555,
      "step": 12500
    },
    {
      "epoch": 0.8111818295270186,
      "grad_norm": 0.017864810302853584,
      "learning_rate": 5.944090852364906e-07,
      "loss": 0.0556,
      "step": 13000
    },
    {
      "epoch": 0.8423811306626732,
      "grad_norm": 0.012722740881145,
      "learning_rate": 5.788094346686634e-07,
      "loss": 0.0557,
      "step": 13500
    },
    {
      "epoch": 0.8735804317983277,
      "grad_norm": 0.009474667720496655,
      "learning_rate": 5.632097841008361e-07,
      "loss": 0.0555,
      "step": 14000
    },
    {
      "epoch": 0.9047797329339823,
      "grad_norm": 0.015165833756327629,
      "learning_rate": 5.476101335330089e-07,
      "loss": 0.0556,
      "step": 14500
    },
    {
      "epoch": 0.9359790340696369,
      "grad_norm": 0.014071664772927761,
      "learning_rate": 5.320104829651816e-07,
      "loss": 0.0556,
      "step": 15000
    },
    {
      "epoch": 0.9671783352052914,
      "grad_norm": 0.010482294484972954,
      "learning_rate": 5.164108323973543e-07,
      "loss": 0.0556,
      "step": 15500
    },
    {
      "epoch": 0.998377636340946,
      "grad_norm": 0.00983516313135624,
      "learning_rate": 5.008111818295269e-07,
      "loss": 0.0555,
      "step": 16000
    },
    {
      "epoch": 0.998377636340946,
      "eval_DDF1": 0.9693135922280521,
      "eval_DDP": 0.9663840543558153,
      "eval_DDR": 0.9722609455591361,
      "eval_loss": 0.05528007820248604,
      "eval_runtime": 544.5904,
      "eval_samples_per_second": 243.207,
      "eval_steps_per_second": 1.901,
      "step": 16000
    },
    {
      "epoch": 1.0295769374766006,
      "grad_norm": 0.014397798106074333,
      "learning_rate": 4.852115312616998e-07,
      "loss": 0.0556,
      "step": 16500
    },
    {
      "epoch": 1.060776238612255,
      "grad_norm": 0.008330846205353737,
      "learning_rate": 4.696118806938724e-07,
      "loss": 0.0555,
      "step": 17000
    },
    {
      "epoch": 1.0919755397479096,
      "grad_norm": 0.016415398567914963,
      "learning_rate": 4.540122301260452e-07,
      "loss": 0.0555,
      "step": 17500
    },
    {
      "epoch": 1.1231748408835642,
      "grad_norm": 0.011716448701918125,
      "learning_rate": 4.3841257955821785e-07,
      "loss": 0.0555,
      "step": 18000
    },
    {
      "epoch": 1.1543741420192188,
      "grad_norm": 0.01451638899743557,
      "learning_rate": 4.228129289903906e-07,
      "loss": 0.0555,
      "step": 18500
    },
    {
      "epoch": 1.1855734431548735,
      "grad_norm": 0.011716043576598167,
      "learning_rate": 4.0721327842256333e-07,
      "loss": 0.0555,
      "step": 19000
    },
    {
      "epoch": 1.2167727442905278,
      "grad_norm": 0.0077451495453715324,
      "learning_rate": 3.9161362785473605e-07,
      "loss": 0.0556,
      "step": 19500
    },
    {
      "epoch": 1.2479720454261825,
      "grad_norm": 0.011947127990424633,
      "learning_rate": 3.7601397728690876e-07,
      "loss": 0.0554,
      "step": 20000
    },
    {
      "epoch": 1.279171346561837,
      "grad_norm": 0.011348678730428219,
      "learning_rate": 3.604143267190814e-07,
      "loss": 0.0555,
      "step": 20500
    },
    {
      "epoch": 1.3103706476974915,
      "grad_norm": 0.012560997158288956,
      "learning_rate": 3.448146761512542e-07,
      "loss": 0.0555,
      "step": 21000
    },
    {
      "epoch": 1.341569948833146,
      "grad_norm": 0.01037729810923338,
      "learning_rate": 3.292150255834269e-07,
      "loss": 0.0557,
      "step": 21500
    },
    {
      "epoch": 1.3727692499688007,
      "grad_norm": 0.014680680818855762,
      "learning_rate": 3.136153750155996e-07,
      "loss": 0.0555,
      "step": 22000
    },
    {
      "epoch": 1.4039685511044553,
      "grad_norm": 0.014301653020083904,
      "learning_rate": 2.9801572444777234e-07,
      "loss": 0.0556,
      "step": 22500
    },
    {
      "epoch": 1.43516785224011,
      "grad_norm": 0.010168147273361683,
      "learning_rate": 2.824160738799451e-07,
      "loss": 0.0555,
      "step": 23000
    },
    {
      "epoch": 1.4663671533757645,
      "grad_norm": 0.012536292895674706,
      "learning_rate": 2.6681642331211777e-07,
      "loss": 0.0555,
      "step": 23500
    },
    {
      "epoch": 1.497566454511419,
      "grad_norm": 0.013980651274323463,
      "learning_rate": 2.5121677274429054e-07,
      "loss": 0.0556,
      "step": 24000
    },
    {
      "epoch": 1.497566454511419,
      "eval_DDF1": 0.9691743140658955,
      "eval_DDP": 0.9662710199414978,
      "eval_DDR": 0.9720951074619563,
      "eval_loss": 0.0552818588912487,
      "eval_runtime": 544.1466,
      "eval_samples_per_second": 243.405,
      "eval_steps_per_second": 1.902,
      "step": 24000
    },
    {
      "epoch": 1.5287657556470735,
      "grad_norm": 0.009779296815395355,
      "learning_rate": 2.3561712217646322e-07,
      "loss": 0.0555,
      "step": 24500
    },
    {
      "epoch": 1.5599650567827281,
      "grad_norm": 0.012166136875748634,
      "learning_rate": 2.2001747160863597e-07,
      "loss": 0.0556,
      "step": 25000
    },
    {
      "epoch": 1.5911643579183825,
      "grad_norm": 0.010857990942895412,
      "learning_rate": 2.0441782104080868e-07,
      "loss": 0.0557,
      "step": 25500
    },
    {
      "epoch": 1.6223636590540371,
      "grad_norm": 0.012107291258871555,
      "learning_rate": 1.888181704729814e-07,
      "loss": 0.0555,
      "step": 26000
    },
    {
      "epoch": 1.6535629601896917,
      "grad_norm": 0.009064101614058018,
      "learning_rate": 1.7321851990515414e-07,
      "loss": 0.0558,
      "step": 26500
    },
    {
      "epoch": 1.6847622613253463,
      "grad_norm": 0.015034457668662071,
      "learning_rate": 1.5761886933732685e-07,
      "loss": 0.0555,
      "step": 27000
    },
    {
      "epoch": 1.715961562461001,
      "grad_norm": 0.016053199768066406,
      "learning_rate": 1.4201921876949954e-07,
      "loss": 0.0557,
      "step": 27500
    },
    {
      "epoch": 1.7471608635966556,
      "grad_norm": 0.009104023687541485,
      "learning_rate": 1.2641956820167226e-07,
      "loss": 0.0555,
      "step": 28000
    },
    {
      "epoch": 1.77836016473231,
      "grad_norm": 0.014295583590865135,
      "learning_rate": 1.10819917633845e-07,
      "loss": 0.0557,
      "step": 28500
    },
    {
      "epoch": 1.8095594658679646,
      "grad_norm": 0.024573519825935364,
      "learning_rate": 9.522026706601771e-08,
      "loss": 0.0557,
      "step": 29000
    },
    {
      "epoch": 1.840758767003619,
      "grad_norm": 0.016032833606004715,
      "learning_rate": 7.962061649819044e-08,
      "loss": 0.0555,
      "step": 29500
    },
    {
      "epoch": 1.8719580681392736,
      "grad_norm": 0.010265512391924858,
      "learning_rate": 6.402096593036316e-08,
      "loss": 0.0555,
      "step": 30000
    },
    {
      "epoch": 1.9031573692749282,
      "grad_norm": 0.01440655067563057,
      "learning_rate": 4.842131536253588e-08,
      "loss": 0.0557,
      "step": 30500
    },
    {
      "epoch": 1.9343566704105828,
      "grad_norm": 0.02042367123067379,
      "learning_rate": 3.28216647947086e-08,
      "loss": 0.0555,
      "step": 31000
    },
    {
      "epoch": 1.9655559715462374,
      "grad_norm": 0.014230797998607159,
      "learning_rate": 1.7222014226881317e-08,
      "loss": 0.0556,
      "step": 31500
    },
    {
      "epoch": 1.996755272681892,
      "grad_norm": 0.01035988051444292,
      "learning_rate": 1.622363659054037e-09,
      "loss": 0.0557,
      "step": 32000
    },
    {
      "epoch": 1.996755272681892,
      "eval_DDF1": 0.9689763765064704,
      "eval_DDP": 0.9653527766243879,
      "eval_DDR": 0.9726272823628811,
      "eval_loss": 0.055285193026065826,
      "eval_runtime": 543.8624,
      "eval_samples_per_second": 243.532,
      "eval_steps_per_second": 1.903,
      "step": 32000
    }
  ],
  "logging_steps": 500,
  "max_steps": 32052,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.528538613996916e+16,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
