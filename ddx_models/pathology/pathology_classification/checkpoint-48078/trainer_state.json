{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 48078,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.031199301135654563,
      "grad_norm": 3.5022308826446533,
      "learning_rate": 5e-05,
      "loss": 3.4752,
      "step": 500
    },
    {
      "epoch": 0.062398602271309125,
      "grad_norm": 3.5182580947875977,
      "learning_rate": 4.9474547059565346e-05,
      "loss": 1.3935,
      "step": 1000
    },
    {
      "epoch": 0.09359790340696368,
      "grad_norm": 4.016259670257568,
      "learning_rate": 4.89490941191307e-05,
      "loss": 0.2052,
      "step": 1500
    },
    {
      "epoch": 0.12479720454261825,
      "grad_norm": 0.6055086255073547,
      "learning_rate": 4.842364117869604e-05,
      "loss": 0.0688,
      "step": 2000
    },
    {
      "epoch": 0.1559965056782728,
      "grad_norm": 0.7314590215682983,
      "learning_rate": 4.7898188238261385e-05,
      "loss": 0.053,
      "step": 2500
    },
    {
      "epoch": 0.18719580681392736,
      "grad_norm": 0.35226306319236755,
      "learning_rate": 4.737273529782673e-05,
      "loss": 0.0378,
      "step": 3000
    },
    {
      "epoch": 0.21839510794958192,
      "grad_norm": 3.4509646892547607,
      "learning_rate": 4.684728235739207e-05,
      "loss": 0.0353,
      "step": 3500
    },
    {
      "epoch": 0.2495944090852365,
      "grad_norm": 5.540560245513916,
      "learning_rate": 4.632182941695742e-05,
      "loss": 0.0334,
      "step": 4000
    },
    {
      "epoch": 0.28079371022089106,
      "grad_norm": 0.10042382776737213,
      "learning_rate": 4.579637647652276e-05,
      "loss": 0.0306,
      "step": 4500
    },
    {
      "epoch": 0.3119930113565456,
      "grad_norm": 0.013101330026984215,
      "learning_rate": 4.527092353608811e-05,
      "loss": 0.0275,
      "step": 5000
    },
    {
      "epoch": 0.34319231249220017,
      "grad_norm": 0.34909719228744507,
      "learning_rate": 4.4745470595653455e-05,
      "loss": 0.0287,
      "step": 5500
    },
    {
      "epoch": 0.3743916136278547,
      "grad_norm": 0.6587061882019043,
      "learning_rate": 4.42200176552188e-05,
      "loss": 0.0278,
      "step": 6000
    },
    {
      "epoch": 0.4055909147635093,
      "grad_norm": 1.0217150449752808,
      "learning_rate": 4.369456471478415e-05,
      "loss": 0.0244,
      "step": 6500
    },
    {
      "epoch": 0.43679021589916384,
      "grad_norm": 0.6633862257003784,
      "learning_rate": 4.3169111774349494e-05,
      "loss": 0.0258,
      "step": 7000
    },
    {
      "epoch": 0.46798951703481845,
      "grad_norm": 0.04405610263347626,
      "learning_rate": 4.264365883391484e-05,
      "loss": 0.0267,
      "step": 7500
    },
    {
      "epoch": 0.499188818170473,
      "grad_norm": 0.185328871011734,
      "learning_rate": 4.211820589348018e-05,
      "loss": 0.0228,
      "step": 8000
    },
    {
      "epoch": 0.5303881193061275,
      "grad_norm": 2.383314847946167,
      "learning_rate": 4.1592752953045526e-05,
      "loss": 0.0237,
      "step": 8500
    },
    {
      "epoch": 0.5615874204417821,
      "grad_norm": 0.2821047902107239,
      "learning_rate": 4.106730001261087e-05,
      "loss": 0.0223,
      "step": 9000
    },
    {
      "epoch": 0.5927867215774366,
      "grad_norm": 1.0066715478897095,
      "learning_rate": 4.054184707217622e-05,
      "loss": 0.0224,
      "step": 9500
    },
    {
      "epoch": 0.6239860227130912,
      "grad_norm": 0.21539147198200226,
      "learning_rate": 4.0016394131741564e-05,
      "loss": 0.0232,
      "step": 10000
    },
    {
      "epoch": 0.6551853238487458,
      "grad_norm": 0.2073809802532196,
      "learning_rate": 3.949094119130691e-05,
      "loss": 0.0228,
      "step": 10500
    },
    {
      "epoch": 0.6863846249844003,
      "grad_norm": 1.2203052043914795,
      "learning_rate": 3.896548825087226e-05,
      "loss": 0.0204,
      "step": 11000
    },
    {
      "epoch": 0.717583926120055,
      "grad_norm": 0.4392479956150055,
      "learning_rate": 3.84400353104376e-05,
      "loss": 0.0211,
      "step": 11500
    },
    {
      "epoch": 0.7487832272557094,
      "grad_norm": 0.3064919114112854,
      "learning_rate": 3.7914582370002947e-05,
      "loss": 0.0211,
      "step": 12000
    },
    {
      "epoch": 0.7799825283913641,
      "grad_norm": 0.27190014719963074,
      "learning_rate": 3.7389129429568284e-05,
      "loss": 0.0191,
      "step": 12500
    },
    {
      "epoch": 0.8111818295270186,
      "grad_norm": 0.3517669439315796,
      "learning_rate": 3.6863676489133634e-05,
      "loss": 0.0198,
      "step": 13000
    },
    {
      "epoch": 0.8423811306626732,
      "grad_norm": 0.7085873484611511,
      "learning_rate": 3.633822354869898e-05,
      "loss": 0.0209,
      "step": 13500
    },
    {
      "epoch": 0.8735804317983277,
      "grad_norm": 0.5444291234016418,
      "learning_rate": 3.581277060826432e-05,
      "loss": 0.0196,
      "step": 14000
    },
    {
      "epoch": 0.9047797329339823,
      "grad_norm": 0.3818207383155823,
      "learning_rate": 3.528731766782967e-05,
      "loss": 0.0196,
      "step": 14500
    },
    {
      "epoch": 0.9359790340696369,
      "grad_norm": 0.2633851170539856,
      "learning_rate": 3.476186472739502e-05,
      "loss": 0.0203,
      "step": 15000
    },
    {
      "epoch": 0.9671783352052914,
      "grad_norm": 0.3156069815158844,
      "learning_rate": 3.423641178696036e-05,
      "loss": 0.0189,
      "step": 15500
    },
    {
      "epoch": 0.998377636340946,
      "grad_norm": 0.598258376121521,
      "learning_rate": 3.371095884652571e-05,
      "loss": 0.0174,
      "step": 16000
    },
    {
      "epoch": 1.0295769374766006,
      "grad_norm": 0.6511788964271545,
      "learning_rate": 3.3185505906091055e-05,
      "loss": 0.021,
      "step": 16500
    },
    {
      "epoch": 1.060776238612255,
      "grad_norm": 0.053267937153577805,
      "learning_rate": 3.266005296565639e-05,
      "loss": 0.0188,
      "step": 17000
    },
    {
      "epoch": 1.0919755397479096,
      "grad_norm": 0.026240194216370583,
      "learning_rate": 3.213460002522174e-05,
      "loss": 0.0179,
      "step": 17500
    },
    {
      "epoch": 1.1231748408835642,
      "grad_norm": 0.5880322456359863,
      "learning_rate": 3.160914708478709e-05,
      "loss": 0.0197,
      "step": 18000
    },
    {
      "epoch": 1.1543741420192188,
      "grad_norm": 0.23610730469226837,
      "learning_rate": 3.108369414435243e-05,
      "loss": 0.0173,
      "step": 18500
    },
    {
      "epoch": 1.1855734431548735,
      "grad_norm": 0.5664566159248352,
      "learning_rate": 3.055824120391778e-05,
      "loss": 0.0195,
      "step": 19000
    },
    {
      "epoch": 1.2167727442905278,
      "grad_norm": 0.19242151081562042,
      "learning_rate": 3.0032788263483126e-05,
      "loss": 0.0189,
      "step": 19500
    },
    {
      "epoch": 1.2479720454261825,
      "grad_norm": 0.5060871839523315,
      "learning_rate": 2.950733532304847e-05,
      "loss": 0.0186,
      "step": 20000
    },
    {
      "epoch": 1.279171346561837,
      "grad_norm": 0.31029489636421204,
      "learning_rate": 2.8981882382613814e-05,
      "loss": 0.0197,
      "step": 20500
    },
    {
      "epoch": 1.3103706476974915,
      "grad_norm": 0.0007057044422253966,
      "learning_rate": 2.845642944217916e-05,
      "loss": 0.0152,
      "step": 21000
    },
    {
      "epoch": 1.341569948833146,
      "grad_norm": 0.1309870183467865,
      "learning_rate": 2.7930976501744505e-05,
      "loss": 0.0185,
      "step": 21500
    },
    {
      "epoch": 1.3727692499688007,
      "grad_norm": 0.1126430556178093,
      "learning_rate": 2.740552356130985e-05,
      "loss": 0.0166,
      "step": 22000
    },
    {
      "epoch": 1.4039685511044553,
      "grad_norm": 0.484756201505661,
      "learning_rate": 2.6880070620875196e-05,
      "loss": 0.017,
      "step": 22500
    },
    {
      "epoch": 1.43516785224011,
      "grad_norm": 0.44061750173568726,
      "learning_rate": 2.635461768044054e-05,
      "loss": 0.0175,
      "step": 23000
    },
    {
      "epoch": 1.4663671533757645,
      "grad_norm": 0.37802088260650635,
      "learning_rate": 2.5829164740005884e-05,
      "loss": 0.0168,
      "step": 23500
    },
    {
      "epoch": 1.497566454511419,
      "grad_norm": 0.2819867432117462,
      "learning_rate": 2.5303711799571235e-05,
      "loss": 0.0163,
      "step": 24000
    },
    {
      "epoch": 1.5287657556470735,
      "grad_norm": 0.0008248713565990329,
      "learning_rate": 2.477825885913658e-05,
      "loss": 0.0174,
      "step": 24500
    },
    {
      "epoch": 1.5599650567827281,
      "grad_norm": 0.015844248235225677,
      "learning_rate": 2.4252805918701922e-05,
      "loss": 0.0182,
      "step": 25000
    },
    {
      "epoch": 1.5911643579183825,
      "grad_norm": 0.6270633935928345,
      "learning_rate": 2.3727352978267266e-05,
      "loss": 0.0148,
      "step": 25500
    },
    {
      "epoch": 1.6223636590540371,
      "grad_norm": 0.6663767695426941,
      "learning_rate": 2.3201900037832614e-05,
      "loss": 0.0181,
      "step": 26000
    },
    {
      "epoch": 1.6535629601896917,
      "grad_norm": 0.41474348306655884,
      "learning_rate": 2.2676447097397958e-05,
      "loss": 0.0174,
      "step": 26500
    },
    {
      "epoch": 1.6847622613253463,
      "grad_norm": 0.13870719075202942,
      "learning_rate": 2.2150994156963305e-05,
      "loss": 0.0176,
      "step": 27000
    },
    {
      "epoch": 1.715961562461001,
      "grad_norm": 0.10493135452270508,
      "learning_rate": 2.162554121652865e-05,
      "loss": 0.0179,
      "step": 27500
    },
    {
      "epoch": 1.7471608635966556,
      "grad_norm": 0.11457763612270355,
      "learning_rate": 2.1100088276093993e-05,
      "loss": 0.0164,
      "step": 28000
    },
    {
      "epoch": 1.77836016473231,
      "grad_norm": 0.6529868245124817,
      "learning_rate": 2.057463533565934e-05,
      "loss": 0.0155,
      "step": 28500
    },
    {
      "epoch": 1.8095594658679646,
      "grad_norm": 0.40371015667915344,
      "learning_rate": 2.0049182395224687e-05,
      "loss": 0.018,
      "step": 29000
    },
    {
      "epoch": 1.840758767003619,
      "grad_norm": 33.63239288330078,
      "learning_rate": 1.9523729454790028e-05,
      "loss": 0.0176,
      "step": 29500
    },
    {
      "epoch": 1.8719580681392736,
      "grad_norm": 0.12840017676353455,
      "learning_rate": 1.8998276514355375e-05,
      "loss": 0.0161,
      "step": 30000
    },
    {
      "epoch": 1.9031573692749282,
      "grad_norm": 0.14458879828453064,
      "learning_rate": 1.847282357392072e-05,
      "loss": 0.0154,
      "step": 30500
    },
    {
      "epoch": 1.9343566704105828,
      "grad_norm": 0.4952111840248108,
      "learning_rate": 1.7947370633486066e-05,
      "loss": 0.0162,
      "step": 31000
    },
    {
      "epoch": 1.9655559715462374,
      "grad_norm": 0.46320098638534546,
      "learning_rate": 1.7421917693051414e-05,
      "loss": 0.0162,
      "step": 31500
    },
    {
      "epoch": 1.996755272681892,
      "grad_norm": 0.172744020819664,
      "learning_rate": 1.6896464752616754e-05,
      "loss": 0.0162,
      "step": 32000
    },
    {
      "epoch": 2.0279545738175466,
      "grad_norm": 0.5970639586448669,
      "learning_rate": 1.63710118121821e-05,
      "loss": 0.0163,
      "step": 32500
    },
    {
      "epoch": 2.0591538749532012,
      "grad_norm": 0.04208989441394806,
      "learning_rate": 1.5845558871747446e-05,
      "loss": 0.0153,
      "step": 33000
    },
    {
      "epoch": 2.0903531760888554,
      "grad_norm": 0.2524701952934265,
      "learning_rate": 1.5320105931312793e-05,
      "loss": 0.0161,
      "step": 33500
    },
    {
      "epoch": 2.12155247722451,
      "grad_norm": 0.40243759751319885,
      "learning_rate": 1.4794652990878138e-05,
      "loss": 0.016,
      "step": 34000
    },
    {
      "epoch": 2.1527517783601646,
      "grad_norm": 2.5540826320648193,
      "learning_rate": 1.4269200050443482e-05,
      "loss": 0.0153,
      "step": 34500
    },
    {
      "epoch": 2.1839510794958192,
      "grad_norm": 0.39551469683647156,
      "learning_rate": 1.3743747110008828e-05,
      "loss": 0.0165,
      "step": 35000
    },
    {
      "epoch": 2.215150380631474,
      "grad_norm": 0.16300615668296814,
      "learning_rate": 1.3218294169574175e-05,
      "loss": 0.0167,
      "step": 35500
    },
    {
      "epoch": 2.2463496817671285,
      "grad_norm": 0.07674593478441238,
      "learning_rate": 1.2692841229139518e-05,
      "loss": 0.0146,
      "step": 36000
    },
    {
      "epoch": 2.277548982902783,
      "grad_norm": 0.12344089895486832,
      "learning_rate": 1.2167388288704865e-05,
      "loss": 0.0153,
      "step": 36500
    },
    {
      "epoch": 2.3087482840384377,
      "grad_norm": 0.541016697883606,
      "learning_rate": 1.1641935348270209e-05,
      "loss": 0.0168,
      "step": 37000
    },
    {
      "epoch": 2.3399475851740923,
      "grad_norm": 0.010163778439164162,
      "learning_rate": 1.1116482407835554e-05,
      "loss": 0.016,
      "step": 37500
    },
    {
      "epoch": 2.371146886309747,
      "grad_norm": 0.30649447441101074,
      "learning_rate": 1.05910294674009e-05,
      "loss": 0.018,
      "step": 38000
    },
    {
      "epoch": 2.402346187445401,
      "grad_norm": 0.616473913192749,
      "learning_rate": 1.0065576526966246e-05,
      "loss": 0.0146,
      "step": 38500
    },
    {
      "epoch": 2.4335454885810557,
      "grad_norm": 1.158751368522644,
      "learning_rate": 9.540123586531591e-06,
      "loss": 0.0159,
      "step": 39000
    },
    {
      "epoch": 2.4647447897167103,
      "grad_norm": 0.7220281958580017,
      "learning_rate": 9.014670646096935e-06,
      "loss": 0.0176,
      "step": 39500
    },
    {
      "epoch": 2.495944090852365,
      "grad_norm": 0.28452420234680176,
      "learning_rate": 8.48921770566228e-06,
      "loss": 0.0156,
      "step": 40000
    },
    {
      "epoch": 2.5271433919880195,
      "grad_norm": 0.022554362192749977,
      "learning_rate": 7.963764765227626e-06,
      "loss": 0.014,
      "step": 40500
    },
    {
      "epoch": 2.558342693123674,
      "grad_norm": 0.2686266601085663,
      "learning_rate": 7.438311824792972e-06,
      "loss": 0.0158,
      "step": 41000
    },
    {
      "epoch": 2.5895419942593287,
      "grad_norm": 0.47778451442718506,
      "learning_rate": 6.912858884358317e-06,
      "loss": 0.0152,
      "step": 41500
    },
    {
      "epoch": 2.620741295394983,
      "grad_norm": 0.04691922664642334,
      "learning_rate": 6.3874059439236616e-06,
      "loss": 0.0162,
      "step": 42000
    },
    {
      "epoch": 2.651940596530638,
      "grad_norm": 0.05429617315530777,
      "learning_rate": 5.861953003489007e-06,
      "loss": 0.0159,
      "step": 42500
    },
    {
      "epoch": 2.683139897666292,
      "grad_norm": 0.21076247096061707,
      "learning_rate": 5.336500063054354e-06,
      "loss": 0.0149,
      "step": 43000
    },
    {
      "epoch": 2.7143391988019467,
      "grad_norm": 0.2525762915611267,
      "learning_rate": 4.8110471226196984e-06,
      "loss": 0.0146,
      "step": 43500
    },
    {
      "epoch": 2.7455384999376014,
      "grad_norm": 0.2501927614212036,
      "learning_rate": 4.285594182185044e-06,
      "loss": 0.0166,
      "step": 44000
    },
    {
      "epoch": 2.776737801073256,
      "grad_norm": 0.00028101238422095776,
      "learning_rate": 3.760141241750389e-06,
      "loss": 0.0157,
      "step": 44500
    },
    {
      "epoch": 2.8079371022089106,
      "grad_norm": 0.18227168917655945,
      "learning_rate": 3.2346883013157344e-06,
      "loss": 0.0156,
      "step": 45000
    },
    {
      "epoch": 2.839136403344565,
      "grad_norm": 0.4062006175518036,
      "learning_rate": 2.7092353608810796e-06,
      "loss": 0.0154,
      "step": 45500
    },
    {
      "epoch": 2.87033570448022,
      "grad_norm": 0.6869008541107178,
      "learning_rate": 2.1837824204464252e-06,
      "loss": 0.0163,
      "step": 46000
    },
    {
      "epoch": 2.901535005615874,
      "grad_norm": 0.1890690177679062,
      "learning_rate": 1.6583294800117704e-06,
      "loss": 0.0166,
      "step": 46500
    },
    {
      "epoch": 2.932734306751529,
      "grad_norm": 0.5130200386047363,
      "learning_rate": 1.1328765395771154e-06,
      "loss": 0.0159,
      "step": 47000
    },
    {
      "epoch": 2.963933607887183,
      "grad_norm": 1.662243366241455,
      "learning_rate": 6.074235991424608e-07,
      "loss": 0.0175,
      "step": 47500
    },
    {
      "epoch": 2.995132909022838,
      "grad_norm": 0.4428052604198456,
      "learning_rate": 8.197065870780613e-08,
      "loss": 0.0145,
      "step": 48000
    }
  ],
  "logging_steps": 500,
  "max_steps": 48078,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.265817437750528e+16,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
